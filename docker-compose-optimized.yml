version: '3.8'

services:
  db:
    image: postgres:15
    restart: always
    shm_size: 256mb  # Increase shared memory for better performance
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    environment:
      - POSTGRES_DB=ticketbot
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    restart: always
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  backend:
    build: .
    restart: always
    command: sh -c "python manage.py migrate && python manage.py collectstatic --noinput && gunicorn core.wsgi:application --bind 0.0.0.0:8000 --timeout 120 --workers 2 --max-requests 1000 --max-requests-jitter 50"
    volumes:
      - .:/app
      - static_volume:/app/backend/staticfiles
    environment:
      - DEBUG=0  # Disable debug mode in production
      - DATABASE_URL=postgres://postgres:postgres@db:5432/ticketbot
      - CELERY_BROKER_URL=redis://redis:6379/0
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - PYTHONPATH=/app/backend:/app
      - STATIC_ROOT=/app/backend/staticfiles
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 512M

  worker_vatican:
    build: .
    restart: always
    init: true  # Critical: Prevents zombie processes
    command: celery -A backend.core worker -l warning -Q vatican,celery --concurrency=2 --max-tasks-per-child=50
    volumes:
      - .:/app
    environment:
      - DATABASE_URL=postgres://postgres:postgres@db:5432/ticketbot
      - CELERY_BROKER_URL=redis://redis:6379/0
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - PYTHONPATH=/app/backend:/app
      - C_FORCE_ROOT=true
      - PYTHONUNBUFFERED=1
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "celery -A backend.core inspect ping -d celery@$$HOSTNAME || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  worker_colosseum:
    build: .
    restart: always
    init: true
    command: celery -A backend.core worker -l warning -Q colosseum --concurrency=2 --max-tasks-per-child=50
    volumes:
      - .:/app
    environment:
      - DATABASE_URL=postgres://postgres:postgres@db:5432/ticketbot
      - CELERY_BROKER_URL=redis://redis:6379/0
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - PYTHONPATH=/app/backend:/app
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "celery -A backend.core inspect ping -d celery@$$HOSTNAME || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G

  beat:
    build: .
    restart: always
    command: celery -A backend.core beat -l warning --scheduler django_celery_beat.schedulers:DatabaseScheduler --max-interval=300
    volumes:
      - .:/app
    environment:
      - DATABASE_URL=postgres://postgres:postgres@db:5432/ticketbot
      - CELERY_BROKER_URL=redis://redis:6379/0
      - PYTHONPATH=/app/backend:/app
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 256M

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    restart: always
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=/api
      - NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=${NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY}
      - CLERK_SECRET_KEY=${CLERK_SECRET_KEY}
      - NODE_ENV=production
    depends_on:
      backend:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 512M

  nginx:
    image: nginx:alpine
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - static_volume:/app/static:ro
    depends_on:
      backend:
        condition: service_healthy
      frontend:
        condition: service_started
    deploy:
      resources:
        limits:
          memory: 128M

  solver:
    build: ./queue_solver
    restart: always
    init: true
    environment:
      - REDIS_HOST=redis
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 512M

  harvester:
    build: ./harvester
    restart: always
    init: true
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 512M

volumes:
  postgres_data:
    external: true
    name: root_postgres_data
  static_volume:
    external: true
    name: root_static_volume
